{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h3V5wnORbCR0"
   },
   "source": [
    "This notebook is designed to transform a pretrained Stylegan2 model to work with conidtional labels.\n",
    "\n",
    "It simply initialises a generator network with the right parameters and copies over the prertained parameters which both networks have in common.\n",
    "\n",
    "In other words, you can take the unconditional FFHQ512 pretrained model, then create a conditional version of the same model ready for effective transfer learning with coniditionallabels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uxy-jmMqyFt0"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import numpy as np\n",
    "from google.colab import drive\n",
    "import json\n",
    "import copy\n",
    "import pickle\n",
    "\n",
    "drive.mount(\"/content/drive\")\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bFgIyFNldKbs"
   },
   "outputs": [],
   "source": [
    "def transfer_weights(model, model_pretrained):\n",
    "    common = []\n",
    "    common_diff_shape = []\n",
    "    other = []\n",
    "    state_dict = model.state_dict()\n",
    "    state_dict_pretrained = model_pretrained.state_dict()\n",
    "    new_model = copy.deepcopy(model)\n",
    "    new_state_dict = {}\n",
    "\n",
    "    for key, value in state_dict.items():\n",
    "        if key in state_dict_pretrained.keys():\n",
    "            if value.shape == state_dict_pretrained[key].shape:\n",
    "                new_state_dict[key] = state_dict_pretrained[key]\n",
    "                common.append(key)\n",
    "            else:\n",
    "                new_state_dict[key] = value\n",
    "                common_diff_shape.append(key)\n",
    "        else:\n",
    "            new_state_dict[key] = value\n",
    "            other.append(key)\n",
    "\n",
    "    new_model.load_state_dict(new_state_dict)\n",
    "    return new_model, {\n",
    "        \"common\": common,\n",
    "        \"common_diff_shape\": common_diff_shape,\n",
    "        \"other\": other,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FuXtkaaGdMqh"
   },
   "outputs": [],
   "source": [
    "%cd /content/\n",
    "!git clone https://github.com/snakch/stylegan2-ada-pytorch.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hcU1d3SocBPn"
   },
   "outputs": [],
   "source": [
    "# Set the path to the original stylegan model\n",
    "\n",
    "!wget https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/transfer-learning-source-nets/ffhq-res512-mirror-stylegan2-noaug.pkl\n",
    "original_model_path = \"/content/ffhq-res512-mirror-stylegan2-noaug.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gS5iMcUI2ndy"
   },
   "outputs": [],
   "source": [
    "%cd stylegan2-ada-pytorch\n",
    "import dnnlib\n",
    "import legacy\n",
    "\n",
    "# Load the pretraine dmodel\n",
    "with dnnlib.util.open_url(original_model_path) as f:\n",
    "    network = legacy.load_network_pkl(f)\n",
    "G_pretrained = network[\"G\"]\n",
    "D_pretrained = network[\"D\"]\n",
    "G_ema_pretrained = network[\"G_ema\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xBv54f4A6Rfz"
   },
   "outputs": [],
   "source": [
    "# Set the dimensionality of the labels and resolution of the netweok\n",
    "# You may have to modify some of the other parameters if dealing with a 1024 network for intance.\n",
    "C_DIM = 7\n",
    "RESOLUTION = 512\n",
    "\n",
    "# Change this to a folder in your drive folder if you want the model to persist\n",
    "OUTPUT_PATH = \"/content/cond_model.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zZHpH__ed6-0"
   },
   "outputs": [],
   "source": [
    "G_kwargs = {\n",
    "    \"class_name\": \"training.networks.Generator\",\n",
    "    \"z_dim\": 512,\n",
    "    \"w_dim\": 512,\n",
    "    \"mapping_kwargs\": {\"num_layers\": 8},\n",
    "    \"synthesis_kwargs\": {\n",
    "        \"channel_base\": 32768,\n",
    "        \"channel_max\": 512,\n",
    "        \"num_fp16_res\": 4,\n",
    "        \"conv_clamp\": 256,\n",
    "    },\n",
    "}\n",
    "D_kwargs = {\n",
    "    \"class_name\": \"training.networks.Discriminator\",\n",
    "    \"block_kwargs\": {},\n",
    "    \"mapping_kwargs\": {},\n",
    "    \"epilogue_kwargs\": {\"mbstd_group_size\": 8},\n",
    "    \"channel_base\": 32768,\n",
    "    \"channel_max\": 512,\n",
    "    \"num_fp16_res\": 4,\n",
    "    \"conv_clamp\": 256,\n",
    "}\n",
    "common_kwargs = {\"c_dim\": C_DIM, \"img_resolution\": RESOLUTION, \"img_channels\": 3}\n",
    "\n",
    "G = dnnlib.util.construct_class_by_name(**G_kwargs, **common_kwargs)\n",
    "D = dnnlib.util.construct_class_by_name(**D_kwargs, **common_kwargs)\n",
    "G_ema = copy.deepcopy(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uvCKdfNf7qlb"
   },
   "outputs": [],
   "source": [
    "new_D, info = transfer_weights(D, D_pretrained)\n",
    "print(\n",
    "    f'{len(info[\"common\"])} common modules, {len(info[\"common_diff_shape\"])} differently shaped modules {len(info[\"other\"])} other modules'\n",
    ")\n",
    "new_G, info = transfer_weights(G, G_pretrained)\n",
    "print(\n",
    "    f'{len(info[\"common\"])} common modules, {len(info[\"common_diff_shape\"])} differently shaped modules {len(info[\"other\"])} other modules'\n",
    ")\n",
    "new_G_ema, info = transfer_weights(G_ema, G_ema_pretrained)\n",
    "print(\n",
    "    f'{len(info[\"common\"])} common modules, {len(info[\"common_diff_shape\"])} differently shaped modules {len(info[\"other\"])} other modules'\n",
    ")\n",
    "\n",
    "\n",
    "new_network = {}\n",
    "new_network[\"training_set_kwargs\"] = network[\"training_set_kwargs\"]\n",
    "new_network[\"augment_pipe\"] = network[\"augment_pipe\"]\n",
    "new_network[\"G\"] = new_G\n",
    "new_network[\"D\"] = new_D\n",
    "new_network[\"G_ema\"] = new_G_ema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "97VyleoG7vua"
   },
   "outputs": [],
   "source": [
    "with open(OUTPUT_PATH, \"wb\") as f:\n",
    "    pickle.dump(new_network, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tRl-3ZmcLTO9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "crJa7340fSBe"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "9i3bYdjn1CkN"
   ],
   "name": "convert_pretrained_stylegan_to_conditional.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
